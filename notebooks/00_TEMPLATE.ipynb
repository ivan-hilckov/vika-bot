{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Start:\n",
    "\n",
    "1. Make sure your `.env` file has `OPENAI_API_KEY`\n",
    "2. Install dependencies: `uv sync`\n",
    "3. Select \"Vika Bot (Python 3.13)\" kernel in Jupyter\n",
    "4. Run all cells\n",
    "5. Change the question and experiment!\n",
    "\n",
    "The template will show you:\n",
    "\n",
    "- Response from OpenAI\n",
    "- Token usage (prompt/completion/total)\n",
    "- **Cost breakdown in USD** (prompt cost + completion cost + total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: gpt-4o-mini\n",
      "Max tokens: 1000\n",
      "Temperature: 0.7\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from tokencost import calculate_prompt_cost, calculate_completion_cost\n",
    "from IPython.display import display, Markdown\n",
    "import json\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "MODEL = os.getenv(\"DEFAULT_MODEL\", \"gpt-4o-mini\")\n",
    "MAX_TOKENS = int(os.getenv(\"MAX_TOKENS\", 1000))\n",
    "TEMPERATURE = float(os.getenv(\"TEMPERATURE\", 0.7))\n",
    "\n",
    "print(f\"Model: {MODEL}\")\n",
    "print(f\"Max tokens: {MAX_TOKENS}\")\n",
    "print(f\"Temperature: {TEMPERATURE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT: 2+2=?\n"
     ]
    }
   ],
   "source": [
    "PROMPT = \"2+2=?\"\n",
    "\n",
    "print(f\"PROMPT: {PROMPT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-C44QB4agB8WEuiUs0hdL2QG6Xs3fX', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='2 + 2 = 4.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1755086343, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_34a54ae93c', usage=CompletionUsage(completion_tokens=8, prompt_tokens=11, total_tokens=19, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "2 + 2 = 4."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 19\n",
      "Total cost (USD): $0.000060\n"
     ]
    }
   ],
   "source": [
    "# Create OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "# Make request to OpenAI\n",
    "try:\n",
    "    messages = [{\"role\": \"user\", \"content\": PROMPT}]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "        max_tokens=MAX_TOKENS,\n",
    "        temperature=TEMPERATURE,\n",
    "    )\n",
    "\n",
    "    # Get the response text\n",
    "    answer = response.choices[0].message.content\n",
    "\n",
    "    # print(response)\n",
    "    # print(json.dumps(response.model_dump(), indent=2, ensure_ascii=False))\n",
    "\n",
    "    display(Markdown(answer))\n",
    "\n",
    "    if response.usage:\n",
    "        print(f\"Total tokens: {response.usage.total_tokens}\")\n",
    "\n",
    "        try:\n",
    "            prompt_cost = calculate_prompt_cost(\n",
    "                messages, \"gpt-4o-2024-05-13\"\n",
    "            )  # model harcoded for remove Warning\n",
    "            completion_cost = calculate_completion_cost(answer, MODEL)\n",
    "            total_cost = prompt_cost + completion_cost\n",
    "\n",
    "            print(f\"Total cost (USD): ${total_cost:.6f}\")\n",
    "        except Exception as cost_error:\n",
    "            print(f\"Could not calculate cost: {cost_error}\")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    print(\"Make sure your OPENAI_API_KEY is set in .env file\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
